{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"tf_gpu","language":"python","name":"tf_gpu"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"demo_llampuga_esteve_no_output.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qm8RDht9TZCf","colab_type":"text"},"source":["# Mask R-CNN - Train on Llampuga Dataset"]},{"cell_type":"code","metadata":{"id":"qZUx99d5TZCg","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import cv2\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import imgaug\n","\n","\n","# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"\")\n","\n","\n","\n","# Import Mask RCNN\n","sys.path.append(\"\")  # To find local version of the library\n","os.chdir(\"/mrcnn\")\n","print(os.getcwd())\n","import inspect\n","import config\n","\n","module = inspect.getmodule(config)\n","module_path = os.path.dirname(module.__file__)\n","print (module_path)\n","\n","import utils\n","module1 = inspect.getmodule(config)\n","module_path1 = os.path.dirname(module1.__file__)\n","import model as modellib\n","import visualize\n","from model import log\n","\n","  \n","    \n","os.chdir(\"\")\n","%matplotlib inline \n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","# Local path to trained weights file\n","#COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n","\n","COCO_MODEL_PATH = os.path.join(\"/mask_rcnn_coco.h5\")\n","#COCO_MODEL_PATH = os.path.join(\"/home/amaya/FOTOPEIX/MASK_RCNN/Mask_RCNN/logs/llampuga20200701T1205/mask_rcnn_llampuga_0029.h5\")\n","print(COCO_MODEL_PATH)\n","# Download COCO trained weights from Releases if needed\n","#if not os.path.exists(COCO_MODEL_PATH):\n","   # utils.download_trained_weights(COCO_MODEL_PATH)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bmj2GMr1TZCl","colab_type":"text"},"source":["## Configurations"]},{"cell_type":"code","metadata":{"id":"P_-R4ZZwTZCl","colab_type":"code","colab":{}},"source":["from datetime import *\n","from dataset import DatasetConfig\n","log_dir='/logs' \n","config = DatasetConfig()\n","config.display()\n","\n","date=datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n","config.save(log_dir,date)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yjgVC6nsTZCo","colab_type":"text"},"source":["## Notebook Preferences"]},{"cell_type":"code","metadata":{"id":"c3f32hjUTZCo","colab_type":"code","colab":{}},"source":["def get_ax(rows=1, cols=1, size=8):\n","    \"\"\"Return a Matplotlib Axes array to be used in\n","    all visualizations in the notebook. Provide a\n","    central point to control graph sizes.\n","    \n","    Change the default size attribute to control the size\n","    of rendered images\n","    \"\"\"\n","    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QVdE54KgTZCr","colab_type":"text"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"41eFlRsDTZCr","colab_type":"code","colab":{}},"source":["from dataset import Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8brkFLiTZCv","colab_type":"code","colab":{}},"source":["# Training dataset\n","dataset_train = Dataset()\n","dataset_train.load_dataset('', '/train3_merged_190_prueba.json')\n","dataset_train.prepare()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7QeY7nQkTZCy","colab_type":"code","colab":{}},"source":["# Validation dataset\n","dataset_val = Dataset()\n","dataset_val.load_dataset('', '/annotations/val2_merged.json')\n","dataset_val.prepare()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"glpem8hsUKfP","colab_type":"code","colab":{}},"source":["dataset = dataset_train\n","image_ids =   np.random.choice(dataset.image_ids, 100) #np.array(dataset.image_ids)\n","print(image_ids)\n","\n","for image_id in image_ids:\n","    image = dataset.load_image(image_id)\n","    mask, class_ids = dataset.load_mask(image_id)\n","    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)\n","    print (class_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KoJSuZcsTZC2","colab_type":"raw"},"source":["# TEST dataset"]},{"cell_type":"code","metadata":{"id":"VoIy6qLiUUeC","colab_type":"code","colab":{}},"source":["dataset_test = Dataset()\n","dataset_test.load_dataset('/home/amaya/FOTOPEIX/MASK_RCNN/test_images/test_llampuga/test_llampuga_todas_cerca_fechas_training/', '/home/asabater/MASK_RCNN/data/toni_test/ann/coco_test.json')\n","dataset_test.prepare()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u1QmWzBnTZC2","colab_type":"text"},"source":["## Create Model"]},{"cell_type":"code","metadata":{"id":"hk8BSXSSTZC3","colab_type":"code","colab":{}},"source":["# Create model in training mode\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                          model_dir=MODEL_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s20lY_F_TZC5","colab_type":"code","colab":{}},"source":["# Which weights to start with?\n","model.load_weights(COCO_MODEL_PATH, by_name=True,\n","                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n","                   \"mrcnn_bbox\", \"mrcnn_mask\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N3L3xAilTZC8","colab_type":"text"},"source":["## AUGMENTATION"]},{"cell_type":"code","metadata":{"id":"H3CkjgKETZC8","colab_type":"code","colab":{}},"source":["# The imgaug library is pretty flexible and make different types of augmentation possible. \n","# The deterministic setting is used because any spatial changes to the image must also be \n","# done to the mask. There are also some augmentors that are unsafe to apply. From the mrcnn\n","# library: \n","# Augmentors that are safe to apply to masks: \n","# [\"Sequential\", \"SomeOf\", \"OneOf\", \"Sometimes\",\"Fliplr\", \n","# \"Flipud\", \"CropAndPad\", \"Affine\", \"PiecewiseAffine\"]\n","# Affine, has settings that are unsafe, so always\n","# test your augmentation on masks\n","\n","import imgaug as ia\n","from imgaug import augmenters as iaa\n","\n","ia.seed(1)\n","\n","# http://imgaug.readthedocs.io/en/latest/source/augmenters.html#sequential\n","seq_of_aug = iaa.Sequential([\n","    iaa.Crop(percent=(0, 0.1)), # random crops\n","    \n","    # horizontally flip 50% of the images\n","    iaa.Fliplr(0.5), \n","\n","    # Gaussian blur to 50% of the images\n","    # with random sigma between 0 and 0.5.\n","    iaa.Sometimes(0.5,\n","        iaa.GaussianBlur(sigma=(0, 0.5))\n","    ),\n","    \n","    # Strengthen or weaken the contrast in each image.\n","    iaa.ContrastNormalization((0.75, 1.5)),\n","    \n","    # Add gaussian noise.\n","    # For 50% of all images, we sample the noise once per pixel.\n","    # For the other 50% of all images, we sample the noise per pixel AND\n","    # channel. This can change the color (not only brightness) of the\n","    # pixels.\n","    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n","    \n","    # Make some images brighter and some darker.\n","    # In 20% of all cases, we sample the multiplier once per channel,\n","    # which can end up changing the color of the images.\n","    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n","    \n","    # Apply affine transformations to each image.\n","    # Scale/zoom them from 90% 5o 110%\n","    # Translate/move them, rotate them\n","    # Shear them slightly -2 to 2 degrees.\n","    iaa.Affine(\n","        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n","        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n","        rotate=(-5, 5),\n","        shear=(-2, 2)\n","    )\n","], random_order=True) # apply augmenters in random order"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Y3psKE-U73c","colab_type":"code","colab":{}},"source":["# Some example augmentations using the seq defined above.\n","image_id = np.random.choice(dataset_train.image_ids, 1)[0] image, image_meta, class_ids, bbox, mask = modellib.load_image_gt( dataset_train, config, image_id, use_mini_mask=False)\n","visualize.display_images( [image], titles=['original'])\n","image_list = [] for i in range(15): image_aug = seq_of_aug.augment_image(image) image_list.append( image_aug)\n","visualize.display_images(image_list, cols=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nbcddBx9TZDA","colab_type":"text"},"source":["## Training\n","\n","Train in two stages:\n","1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n","\n","2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."]},{"cell_type":"code","metadata":{"id":"L2l7AMbRTZDA","colab_type":"code","colab":{}},"source":["# Train the head branches\n","# Passing layers=\"heads\" freezes all layers except the head\n","# layers. You can also pass a regular expression to select\n","# which layers to train bcy name pattern.\n","import keras\n","model.keras_model.metrics_tensors = []\n","augmentation=seq_of_aug\n","augmentation = imgaug.augmenters.Sometimes(0.5, [\n","                    imgaug.augmenters.Fliplr(0.5),\n","                    #imgaug.augmenters.Flipud(0.5),\n","                    #imgaug.augmenters.Affine(\n","                                   # rotate=(-15,15),  # rotate by -45 to +45 degrees\n","                                   # shear=(-2, 2),  # shear by -16 to +16 degrees\n","                                    #order=1,  # order=[0, 1],  # use nearest neighbour or bilinear interpolation (fast)\n","                                   # cval=0,  # cval=(0, 255),  # if mode is constant, use a cval between 0 and 255\n","                                  # mode='constant'\n","                                    ## mode=ia.ALL  # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n","                              # )\n","                ])\n","\n","#augmentation1 = imgaug.augmenters.Sometimes(5/6,imgaug.augmenters.OneOf(\n","                                            #[\n","                                           # imgaug.augmenters.Fliplr(0.5), \n","                                           # imgaug.augmenters.Flipud(0.5), \n","                                            #imgaug.augmenters.Affine(rotate=(90)) \n","                                           # imgaug.augmenters.Affine(rotate=(-15, 15)) \n","                                           # ]                                             \n","                                       # )\n","                                  # )\n","model.train(dataset_train, dataset_val, \n","            learning_rate=config.LEARNING_RATE, \n","            epochs=100, \n","            layers='all',\n","            augmentation=seq_of_aug\n","           )\n","#model.train(dataset_train, dataset_val, \n","           #learning_rate=config.LEARNING_RATE ,\n","            # epochs=50, \n","           #  layers=\"all\",\n","            # augmentation=augmentation\n","           # )\n"," \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f-kiRY4OTZDD","colab_type":"text"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"575u6XuETZDE","colab_type":"code","colab":{}},"source":["from dataset import InferenceConfig\n","\n","inference_config = InferenceConfig()\n","\n","#bad_testing_samples = [9]\n","\n","# Recreate the model in inference mode\n","model = modellib.MaskRCNN(mode=\"inference\", \n","                          config=inference_config,\n","                          model_dir=MODEL_DIR)\n","\n","# Get path to saved weights\n","# Either set a specific path or find last trained weights\n","#model_path = os.path.join(ROOT_DIR, \"../data/models/mask_rcnn_hake_0100.h5\")\n","#model_path = os.path.join(\"/home/instman/FOTOPEIX/INSTANCE_SEGMENTATION/2018-dlcv-team5-master/Mask_RCNN/data/models/mask_rcnn_hake_0100.h5\")\n","model_path = os.path.join(\"/llampuga20200716T1119/mask_rcnn_llampuga_0068.h5\")\n","# model_path = model.find_last()\n","\n","# Load trained weights\n","print(\"Loading weights from \", model_path)\n","model.load_weights(model_path, by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GtwvP9u9TZDH","colab_type":"text"},"source":["## EVALUACIÓN DE RESULTADOS"]},{"cell_type":"code","metadata":{"id":"IYztKINNTZDI","colab_type":"code","colab":{}},"source":["# Compute VOC-Style mAP @ IoU=0.5\n","# Running on 5 images. Increase for better accuracy.\n","\n","image_ids = np.random.choice(dataset_val.image_ids,20)  #np.array(dataset_val.image_ids) #\n","\n","APs = []\n","prs = []\n","rca = []\n","ovl = []\n","#a=image_ids[7]\n","savedir=''\n","#bad_testing_samples = [8,24]\n","\n","for image_id in image_ids:\n","    mat=[]\n","    mat1=[]\n","    # Skip wrongly tagged images (ugly, but we could not understand why tags for these images is not working)\n","    #if image_id in bad_testing_samples:\n","        # continue\n","    # Load image and ground truth data\n","    print('image id: ' + str(image_id))\n","    \n","    \n","    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n","        modellib.load_image_gt(dataset_val, inference_config,\n","                               image_id, use_mini_mask=False)\n","    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n","    # Run object detection\n","    results = model.detect([image], verbose=0)\n","    r = results[0]\n","    #if   r['masks'].all()== False:\n","        #break\n","    # Compute AP\n","    AP, precisions, recalls, overlaps =\\\n","        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n","                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n","    APs.append(AP)\n","    results = model.detect([image], verbose=0)\n","    r = results[0]\n","   \n","\n","    #visualize.display_instances(image_id, gt_bbox, gt_mask, gt_class_id, \n","                            #dataset_val.class_names, ax=get_ax(size=20))\n","\n","#visualize.display_weight_stats(model)\n","    \n","    filename=str(image_id)\n","    visualize.display_differences(image,\n","                        gt_bbox, gt_class_id, gt_mask,\n","                        r['rois'], r['class_ids'], r['scores'],r['masks'],\n","                        dataset_val.class_names, title=\"\", ax=get_ax(size=20),\n","                        show_mask=True, show_box=True,\n","                        iou_threshold=0.5, score_threshold=0.5)\n","    \n","    plt.savefig(savedir+filename+'_differences.jpg')\n","    \n","    \n","    ma=len(results[0]['rois'])\n","    mi=list(map(str, range(ma)))\n","\n","    visualize.display_instances(image, r['rois'],  r['masks'],r['class_ids'], \n","                            dataset_val.class_names, r['scores'], ax=get_ax(size=20),captions=mi)\n","    plt.savefig(savedir+filename+'_segmentation.jpg')\n","    \n","   #print( dataset_test.source_image_link)  \n","    \n","            \n","   # np.savetxt(savedir+filename+'_score.txt', r['scores'], fmt='%1.3f')\n","    \n","   # np.savetxt(savedir+filename+'_class_ids.txt', r['class_ids'], fmt='%4d')\n","   # np.savetxt(savedir+filename+'_class_ids_gt.txt', gt_class_id, fmt='%4d')\n","    #np.savetxt(savedir+filename+'_bbox_gt.txt', gt_bbox, fmt='%4d')                  \n","    \n","    rois = results[0]['rois']\n","    for i, r in enumerate(rois):\n","        y1, x1, y2, x2 = r\n","        \n","        m=[x1,x2,y1,y2]\n","        \n","        mat.append(m)    \n","   # np.savetxt(savedir+filename+'_bbox.txt', mat,fmt='%4d %4d %4d %4d')   \n","   \n","    #print(\"precision: \", prs)\n","    #print(\"recall: \", rca)\n","    #print(\"overlaps: \", ovl)\n","\n","\n","   # np.savetxt(savedir+filename+'pre_reca.txt', np.column_stack([precisions,recalls]))\n","\n","print(\"mAP: \", np.mean(APs))\n","\n","#np.savetxt(savedir+'class_names.txt', dataset_val.class_names, fmt='%s')  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yeqbf8W4TZDK","colab_type":"text"},"source":["## MATRIZ DE CONFUSION"]},{"cell_type":"code","metadata":{"id":"43qUDVBwTZDK","colab_type":"code","colab":{}},"source":["import pandas as pd\n","gt_tot = np.array([])\n","pred_tot = np.array([])\n","mAP_ = []\n","\n","image_ids = np.random.choice(dataset_val.image_ids,1)\n","\n","\n","for image_id in image_ids:\n","\n","    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n","    modellib.load_image_gt(dataset_val, config, image_id, use_mini_mask=False)\n","    info = dataset_val.image_info[image_id]\n","    #print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id,\n","    #dataset.image_reference(image_id)))\n","    # Run object detection\n","    results = model.detect([image], verbose=1)\n","\n","    # Display results\n","    #ax = get_ax(1)\n","    r = results[0]\n","    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n","                            dataset_val.class_names, r['scores'], ax=get_ax(size=20),\n","                            title=\"Predictions\")\n","    #log(\"gt_class_id\", gt_class_id)\n","    #log(\"gt_bbox\", gt_bbox)\n","    #log(\"gt_mask\", gt_mask)\n","    gt, pred = utils.gt_pred_lists(gt_class_id, gt_bbox, r['class_ids'], r['rois'], iou_tresh = 0.4)\n","    gt_tot = np.append(gt_tot, gt)\n","    pred_tot = np.append(pred_tot, pred)\n","    #precision_, recall_, AP_ = utils.compute_precision_recall_map(gt_tot, pred_tot)\n","    AP_, precision_, recall_, overlap_ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n","                                      r['rois'], r['class_ids'], r['scores'], r['masks'], iou_threshold = 0.4)\n","    print(\"the actual len of the gt vect is : \", len(gt_tot))\n","    print(\"the actual len of the pred vect is : \", len(pred_tot))\n","    print(\"the actual precision is : \", precision_)\n","    print(\"the actual recall is : \", recall_)\n","#print(\"the actual overlaps is : \", overlap_)\n","    mAP_.append(AP_)\n","    print(\"the actual average precision : \", AP_)\n","    print(\"the actual mean average precision : \", sum(mAP_)/len(mAP_))\n","\n","directory = 'output'\n","gt_pred_tot_json = {\"gt_tot\" : gt_tot.astype(int), \"pred_tot\" : pred_tot.astype(int)}\n","df = pd.DataFrame(gt_pred_tot_json)\n","\n","import os\n","if not os.path.exists(directory):\n","    os.makedirs(directory)\n","df.to_json(os.path.join(directory, 'gt_pred_test.json'))\n","\n","from mrcnn import confusion_matrix_pretty_print\n","\n","confusion_matrix_pretty_print.plot_confusion_matrix_from_data( gt_tot, pred_tot,columns=None, annot=True, cmap=\"Oranges\",\n","      fmt='.2f', fz=11, lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='lin')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XpexMohTTZDN","colab_type":"text"},"source":["## INFERENCIA  EN IMÁGENES DE LLAMPUGA DE LONJA"]},{"cell_type":"code","metadata":{"id":"P9Q-uuFWTZDN","colab_type":"code","colab":{}},"source":["import os\n","import numpy as num\n","from PIL import Image\n","from PIL.ExifTags import TAGS\n","name=[]\n","data1=[]\n","vta=[]\n","ord1=[]\n","emb=[]\n","pes=[]\n","caj=[]\n","fao=[]\n","DATO=[]\n","savedir=''\n","\n","#DEBE ENTRAR EN LAS CARPETAS QUE SE ENCUENTRE CON EL NOMBRE OPPM_Subasta_\"fecha\"\n","\n","for root, dirs, files in os.walk(\"/OPMM_Subasta_2020-09-01/\"):  \n","    for filename in files:\n","        mat=[]\n","\n","        image=Image.open(root+filename)\n","        exifdata = image._getexif()\n","        \n","        for tag_id in exifdata:\n","#    # get the tag name, instead of human unreadable tag id\n","            tag = TAGS.get(tag_id, tag_id)\n","            data = exifdata.get(tag_id)\n","#    # decode bytes \n","        if isinstance(data, bytes):\n","            \n","            data = data.decode()\n","               \n","            fao= data[96] + data[98] + data[100]\n","            ord1 = data[28]\n","            caj= data[82] + data[84] \n","               \n","            if (fao == 'DOL') and (ord1 == '1') and (caj == '01'):\n","                print(filename)\n","                vta=data[10] +data[12]+data[14]+data[16]   \n","                emb=data[40]+data[42]+data[44]+data[47]\n","                pes= data[60]+data[62]+data[64]+data[66]+data[68]\n","                #DAT =  num.column_stack((filename,vta,ord1,emb,pes,caj, fao))\n","               # DATO.append(DAT)\n","                    #####EJECUTAR INFERENCIA DE MASKRCNN \n","                image=cv2.imread(root+filename)\n","                print(filename)\n","                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","                image, window, scale, padding, crop = utils.resize_image(\n","                image,\n","                min_dim=config.IMAGE_MIN_DIM,\n","                min_scale=config.IMAGE_MIN_SCALE,\n","                max_dim=config.IMAGE_MAX_DIM,\n","                mode=config.IMAGE_RESIZE_MODE)\n","       \n","        \n","                results = model.detect([image], verbose=1)\n","\n","                r = results[0]\n","      \n","                ma=len(results[0]['rois'])\n","                mi=list(map(str, range(ma)))\n","                rois = results[0]['rois']\n","                \n","                \n","                visualize.display_instances(image, r['rois'],  r['masks'],r['class_ids'], \n","                            dataset_val.class_names, r['scores'], ax=get_ax(size=20),captions=mi)\n","         \n","                np.savetxt(savedir+filename+'_score.txt', r['scores'], fmt='%1.3f')\n","    \n","                np.savetxt(savedir+filename+'_class_ids.txt', r['class_ids'], fmt='%4d')\n","                for i, r in enumerate(rois):\n","                    y1, x1, y2, x2 = r\n","        \n","                    m=[x1,x2,y1,y2]\n","        \n","                    mat.append(m)\n","                np.savetxt(savedir+filename+'_bbox.txt', mat,fmt='%4d %4d %4d %4d')\n","                #np.savetxt(savedir+'DATO.txt',DATO,fmt='%s %s %s %s %s %s %s')\n","            else:\n","                     \n","                print(filename + ' no llampuga')"],"execution_count":null,"outputs":[]}]}